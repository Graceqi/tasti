{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import swag\n",
    "import json\n",
    "import tasti\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from scipy.spatial import distance\n",
    "import torchvision.transforms as transforms\n",
    "from collections import defaultdict\n",
    "from tqdm.autonotebook import tqdm\n",
    "\n",
    "class VideoDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, video_fp, list_of_idxs=[], transform_fn=lambda x: x):\n",
    "        self.video_fp = video_fp\n",
    "        self.list_of_idxs = []\n",
    "        self.transform_fn = transform_fn\n",
    "        self.video_metadata = json.load(open(self.video_fp + '.json', 'r'))\n",
    "        self.cum_frames = np.array(self.video_metadata['cum_frames'])\n",
    "        self.cum_frames = np.insert(self.cum_frames, 0, 0)\n",
    "        self.length = self.cum_frames[-1]\n",
    "        self.cap = swag.VideoCapture(self.video_fp)\n",
    "        self.current_idx = 0\n",
    "        self.init()\n",
    "        \n",
    "    def init(self):\n",
    "        if len(self.list_of_idxs) == 0:\n",
    "            self.frames = None\n",
    "        else:\n",
    "            self.frames = []\n",
    "            for idx in tqdm(self.list_of_idxs, desc=\"Video\"):\n",
    "                self.seek(idx)\n",
    "                frame = self.read()\n",
    "                self.frames.append(frame)\n",
    "            \n",
    "    def transform(self, frame):\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        frame = self.transform_fn(frame)\n",
    "        return frame\n",
    "\n",
    "    def seek(self, idx):\n",
    "        if self.current_idx != idx:\n",
    "            self.cap.set(cv2.CAP_PROP_POS_FRAMES, idx - 1)\n",
    "            self.current_idx = idx\n",
    "        \n",
    "    def read(self):\n",
    "        _, frame = self.cap.read()\n",
    "        frame = self.transform(frame)\n",
    "        self.current_idx += 1\n",
    "        return frame\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.length if len(self.list_of_idxs) == 0 else len(self.list_of_idxs)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if len(self.list_of_idxs) == 0:\n",
    "            self.seek(idx)\n",
    "            frame = self.read()\n",
    "        else:\n",
    "            frame = self.frames[idx]\n",
    "        return frame   \n",
    "\n",
    "class LabelDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, labels_fp, length):\n",
    "        df = pd.read_csv(labels_fp)\n",
    "        df = df[df['object_name'].isin(['car', 'bus'])]\n",
    "        frame_to_rows = defaultdict(list)\n",
    "        for row in df.itertuples():\n",
    "            frame_to_rows[row.frame].append(row)\n",
    "        labels = []\n",
    "        for frame_idx in range(length):\n",
    "            labels.append(frame_to_rows[frame_idx])\n",
    "        self.labels = labels\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.labels[idx]\n",
    "        \n",
    "def night_street_embedding_dnn_transform_fn(frame):\n",
    "    xmin, xmax, ymin, ymax = 0, 1750, 540, 1080\n",
    "    frame = frame[ymin:ymax, xmin:xmax]\n",
    "    frame = cv2.resize(frame, (224, 224))\n",
    "    frame = torchvision.transforms.functional.to_tensor(frame)\n",
    "    return frame\n",
    "\n",
    "def night_street_target_dnn_transform_fn(frame):\n",
    "    xmin, xmax, ymin, ymax = 0, 1750, 540, 1080\n",
    "    frame = frame[ymin:ymax, xmin:xmax]\n",
    "    frame = torchvision.transforms.functional.to_tensor(frame)\n",
    "    return frame\n",
    "\n",
    "def night_street_is_close_helper(label1, label2):\n",
    "    if len(label1) != len(label2):\n",
    "        return False\n",
    "    counter = 0\n",
    "    for obj1 in label1:\n",
    "        xavg1 = (obj1.xmin + obj1.xmax) / 2.0\n",
    "        yavg1 = (obj1.ymin + obj1.ymax) / 2.0\n",
    "        coord1 = [xavg1, yavg1]\n",
    "        expected_counter = counter + 1\n",
    "        for obj2 in label2:\n",
    "            xavg2 = (obj2.xmin + obj2.xmax) / 2.0\n",
    "            yavg2 = (obj2.ymin + obj2.ymax) / 2.0\n",
    "            coord2 = [xavg2, yavg2]\n",
    "            if distance.euclidean(coord1, coord2) < 100:\n",
    "                counter += 1\n",
    "                break\n",
    "        if expected_counter != counter:\n",
    "            break\n",
    "    return len(label1) == counter\n",
    "        \n",
    "class NightStreetOfflineIndex(tasti.Index):\n",
    "    def get_target_dnn(self):\n",
    "        model = torch.nn.Identity()\n",
    "        return model\n",
    "        \n",
    "    def get_embedding_dnn(self):\n",
    "        model = torchvision.models.resnet18(pretrained=True, progress=True)\n",
    "        model.fc = torch.nn.Linear(512, 128)\n",
    "        return model\n",
    "    \n",
    "    def get_target_dnn_dataset(self):\n",
    "        video = VideoDataset(\n",
    "            video_fp='/lfs/1/jtguibas/data/2017-12-17',\n",
    "            transform_fn=night_street_target_dnn_transform_fn\n",
    "        )\n",
    "        return video\n",
    "    \n",
    "    def get_embedding_dnn_dataset(self):\n",
    "        video = VideoDataset(\n",
    "            video_fp='/lfs/1/jtguibas/data/2017-12-17',\n",
    "            transform_fn=night_street_embedding_dnn_transform_fn\n",
    "        )\n",
    "        return video\n",
    "    \n",
    "    def override_target_dnn_cache(self, target_dnn_cache):\n",
    "        labels = LabelDataset(\n",
    "            labels_fp='/lfs/1/jtguibas/data/labels/jackson-town-square-2017-12-17.csv',\n",
    "            length=len(target_dnn_cache)\n",
    "        )\n",
    "        return labels\n",
    "    \n",
    "    def is_close(self, label1, label2):\n",
    "        objects = set()\n",
    "        for obj in (label1 + label2):\n",
    "            objects.add(obj.object_name)\n",
    "        for current_obj in list(objects):\n",
    "            label1_disjoint = [obj for obj in label1 if obj.object_name == current_obj]\n",
    "            label2_disjoint = [obj for obj in label2 if obj.object_name == current_obj]\n",
    "            is_redundant = night_street_is_close_helper(label1_disjoint, label2_disjoint)\n",
    "            if not is_redundant:\n",
    "                return False\n",
    "        return True\n",
    "\n",
    "class NightStreetOfflineConfig(tasti.IndexConfig):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.do_mining = False\n",
    "        self.do_training = False\n",
    "        self.do_infer = False\n",
    "        self.do_bucketting = True\n",
    "        \n",
    "        self.batch_size = 8\n",
    "        self.nb_train = 3000\n",
    "        self.train_margin = 1.0\n",
    "        self.train_lr = 1e-4\n",
    "        self.max_k = 5\n",
    "        self.nb_buckets = 7000\n",
    "        self.nb_training_its = 12000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/lfs/1/jtguibas/anaconda3/envs/TASTI/lib/python3.7/site-packages/numba/np/ufunc/parallel.py:355: NumbaWarning: The TBB threading layer requires TBB version 2019.5 or later i.e., TBB_INTERFACE_VERSION >= 11005. Found TBB_INTERFACE_VERSION = 9002. The TBB threading layer is disabled.\n",
      "  warnings.warn(problem)\n",
      "RandomBucketter: 100%|██████████| 1749/1749 [00:28<00:00, 61.45it/s]\n",
      "FPFBucketter: 100%|██████████| 5250/5250 [01:32<00:00, 56.58it/s]\n",
      "100%|██████████| 973136/973136 [03:50<00:00, 4214.31it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "153b23f17332405683c4e441dfb0b753",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Target DNN Invocations', max=7000.0, style=ProgressStyle(…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "config = NightStreetOfflineConfig()\n",
    "index = NightStreetOfflineIndex(config)\n",
    "index.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13f2078c5f5c4c20b05781cfb8143579",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Propagation', max=973136.0, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results\n",
      "=======\n",
      "Initial Estimate: 325960.22655864124\n",
      "Debiased Estimate: 353221.4430812905\n",
      "Samples: 19875\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'initial_estimate': 325960.22655864124,\n",
       " 'debiased_estimate': 353221.4430812905,\n",
       " 'samples': 19875}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class NightStreetAggregateQuery(tasti.AggregateQuery):\n",
    "    def score(self, target_dnn_output):\n",
    "        return len(target_dnn_output)\n",
    "    \n",
    "class NightStreetSUPGPrecisionQuery(tasti.SUPGPrecisionQuery):\n",
    "    def score(self, target_dnn_output):\n",
    "        return 1.0 if len(target_dnn_output) > 0 else 0.0\n",
    "    \n",
    "class NightStreetSUPGRecallQuery(tasti.SUPGRecallQuery):\n",
    "    def score(self, target_dnn_output):\n",
    "        return 1.0 if len(target_dnn_output) > 0 else 0.0\n",
    "    \n",
    "query = NightStreetAggregateQuery(index)\n",
    "query.execute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b87d9322681d435f98a36c68bc4c885d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Propagation', max=973136.0, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results\n",
      "=======\n",
      "Initial Estimate: 325960.22655864124\n",
      "Debiased Estimate: 353205.94067314616\n",
      "Samples: 20592\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'initial_estimate': 325960.22655864124,\n",
       " 'debiased_estimate': 353205.94067314616,\n",
       " 'samples': 20592}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query.execute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1238da7c87204996b6d69e09af6c7b3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Propagation', max=973136.0, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results\n",
      "=======\n",
      "Initial Estimate: 325960.22655864124\n",
      "Debiased Estimate: 350806.3065750688\n",
      "Samples: 20233\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'initial_estimate': 325960.22655864124,\n",
       " 'debiased_estimate': 350806.3065750688,\n",
       " 'samples': 20233}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query.execute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55143ff71eec48699b6d2b470b4ccb0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Propagation', max=973136.0, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results\n",
      "=======\n",
      "Number of Calls: 3080\n",
      "Indexes: [2550, 53204, 55091, 29684, 104868, 248130, 79982, 201609, 101777, 119623]\n"
     ]
    }
   ],
   "source": [
    "import tasti\n",
    "import numpy as np\n",
    "import supg.datasource as datasource\n",
    "from tqdm.autonotebook import tqdm\n",
    "from blazeit.aggregation.samplers import ControlCovariateSampler\n",
    "from supg.sampler import ImportanceSampler\n",
    "from supg.selector import ApproxQuery\n",
    "from supg.selector import RecallSelector, ImportancePrecisionTwoStageSelector\n",
    "\n",
    "class BaseQuery:\n",
    "    def __init__(self, index):\n",
    "        self.index = index\n",
    "        \n",
    "    def score(self, target_dnn_output):\n",
    "        raise NotImplementedError\n",
    "        \n",
    "    def propagate(self, target_dnn_cache, reps, topk_reps, topk_distances):\n",
    "        score_fn = self.score\n",
    "        y_true = np.array(\n",
    "            [tasti.DNNOutputCacheFloat(target_dnn_cache, score_fn, idx) for idx in range(len(topk_reps))]\n",
    "        )\n",
    "        y_pred = np.zeros(len(topk_reps))\n",
    "\n",
    "        for i in tqdm(range(len(y_pred)), 'Propagation'):\n",
    "            weights = topk_distances[i]\n",
    "            weights = weights / weights.sum()\n",
    "            counts = y_true[topk_reps[i]]\n",
    "            y_pred[i] =  np.sum(counts * weights)\n",
    "        return y_pred, y_true\n",
    "        \n",
    "    def execute(self):\n",
    "        raise NotImplementedError\n",
    "           \n",
    "class LimitQuery(BaseQuery):\n",
    "    def score(self, target_dnn_output):\n",
    "        return len(target_dnn_output)\n",
    "    \n",
    "    def execute(self, want_to_find, GAP=300):\n",
    "        y_pred, y_true = self.propagate(\n",
    "            self.index.target_dnn_cache,\n",
    "            self.index.reps, self.index.topk_reps, self.index.topk_dists\n",
    "        )\n",
    "        order = np.argsort(y_pred)[::-1]\n",
    "        ret_inds = []\n",
    "        visited = set()\n",
    "        nb_calls = 0\n",
    "        for ind in order:\n",
    "            if ind in visited:\n",
    "                continue\n",
    "            nb_calls += 1\n",
    "            if float(y_true[ind]) >= want_to_find:\n",
    "                ret_inds.append(ind)\n",
    "                for offset in range(-GAP, GAP+1):\n",
    "                    visited.add(offset + ind)\n",
    "            if len(ret_inds) >= 10:\n",
    "                break\n",
    "                \n",
    "        print('Results')\n",
    "        print('=======')\n",
    "        print('Number of Calls:', nb_calls)\n",
    "        print('Indexes:', ret_inds)\n",
    "        return {'nb_calls': nb_calls, 'ret_inds': ret_inds}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
